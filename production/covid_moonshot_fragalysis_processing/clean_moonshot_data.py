"""
This script is used to clean the moonshot data.
Uses the cache generated by the asapdiscovery-data package (asapdiscovery.modeling.protein_prep.ProteinPrepper)
"""

from pathlib import Path
from asapdiscovery.data.schema.complex import Complex, PreppedComplex
from asapdiscovery.modeling.protein_prep import ProteinPrepper
import json
from tqdm import tqdm
import argparse
from collections import defaultdict
from logging import Logger


def args():
    parser = argparse.ArgumentParser()
    parser.add_argument('-i', '--input_cache', type=Path, help='Path to input cache generated by the asapdiscovery-data package')
    parser.add_argument('-o', '--output_cache', type=Path, help='Path to output cache to be generated by this script')
    return parser.parse_args()


def clean_moonshot_data(data_dir, output_dir):
    schema_paths = list(data_dir.glob("Mpro-P*/*.json"))
    logger = Logger()
    logger.info(f"Found {len(schema_paths)} complexes in the cache")
    complexes = [PreppedComplex(**json.load(open(complex_json, 'r'))) for complex_json in tqdm(schema_paths)]

    # Get just a single structure for each molecule
    logger.info(f"Selecting a single structure for each ligand")
    new_structures = defaultdict(None)
    for complex in complexes:
        old_complex = new_structures.get(complex.ligand.smiles, None)

        # if we don't have one yet, add it
        if not old_complex:
            new_structures[complex.ligand.smiles] = complex
            continue

        # this is to compare the dataset and the chain used
        old_dataset_number = old_complex.target.target_name.split("_")[0]
        old_dataset_letter = old_complex.target.target_name.split("_")[-1]
        new_dataset_number = complex.target.target_name.split("_")[0]
        new_dataset_letter = complex.target.target_name.split("_")[-1]

        # we want later datasets and chain A if possible
        if new_dataset_number > old_dataset_number:
            new_structures[complex.ligand.smiles] = complex
            continue
        if new_dataset_number == old_dataset_number and new_dataset_letter < old_dataset_letter:
            new_structures[complex.ligand.smiles] = complex
            continue
    logger.info(f"Selected {len(new_structures)} structures. Writing to cache...")

    protein_prepper = ProteinPrepper()
    protein_prepper.cache(list(new_structures.values()),
                          cache_dir=output_dir)
    with open(data_dir.parent / "20240403_fragalysis_p_series_curated_cache" / "README.md", 'w') as f:
        f.write(
            f"This cache was created by selecting a single structure for each ligand (identified by the smiles string, "
            f"not the compound ID) in the P series from the fragalysis cache: '{data_dir.absolute()}'. "
            f"The selection was based on the dataset number and letter, with the highest dataset number and lowest "
            f"letter being selected (i.e. datasets that were collected later and chain A if possible). "
            f"This was performed by '{__file__}'")

    logger.info(f"Cache written to {output_dir}!")


if __name__ == '__main__':
    args = args()
    clean_moonshot_data(args.input_cache, args.output_cache)